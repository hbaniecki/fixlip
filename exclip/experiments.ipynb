{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77044ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "import clip\n",
    "import torch\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapiq\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "sys.path.append('../')\n",
    "import src\n",
    "PATH = \"../data\"\n",
    "\n",
    "from wrapper import exCLIP\n",
    "\n",
    "def denormalize(img, mean, std):\n",
    "    return img * torch.tensor(std).view(3, 1, 1) + torch.tensor(mean).view(3, 1, 1)\n",
    "image_mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "image_std = (0.26862954, 0.26130258, 0.27577711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"exclip\"\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "# MODEL_NAME = \"openai/clip-vit-base-patch16\"\n",
    "# model, preprocess = clip.load(\"ViT-B/16\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463af64",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69957bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"black dog next to a yellow hydrant\"\n",
    "text_processed = clip.tokenize([input_text]).to(device)\n",
    "input_image = Image.open(os.path.join(\"..\", \"assets\", \"dog_and_hydrant.png\"))\n",
    "image_preprocessed = preprocess(input_image).to(device).unsqueeze(0)\n",
    "\n",
    "explanation = exCLIP(model, device=device)\n",
    "output = explanation.attribute_prediction(\n",
    "    text_processed, \n",
    "    image_preprocessed, \n",
    "    text_layer=11, \n",
    "    image_layer=11,\n",
    "    N=20\n",
    ")\n",
    "crossmodal_interactions = output[1:-1,1:]\n",
    "gv = src.utils.convert_array_to_second_order(crossmodal_interactions, index=\"exclip\")\n",
    "gv.save(\"../example/dog_and_hydrant_exclip.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c41aa5",
   "metadata": {},
   "source": [
    "### insertion/deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_RESULTS = \"../results\"\n",
    "PATH_INPUT = \"../results/mscoco\"\n",
    "\n",
    "dataset = datasets.load_dataset(\n",
    "    \"clip-benchmark/wds_mscoco_captions\",\n",
    "    split=\"test\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "start, stop = 0, 1000\n",
    "df_results = pd.read_csv(os.path.join(PATH_RESULTS, MODEL_NAME, \"mscoco_predictions.csv\"), index_col=0)\n",
    "top_ids = df_results.sort_values(\"logit\", ascending=False).iloc[start:stop, :].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_details = {MODE: {}}\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'input': [], \n",
    "    'mode': [], \n",
    "    'mean': [],\n",
    "    'mean_normalized': []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 0\n",
    "for i, d in enumerate(dataset):\n",
    "    if i not in top_ids:\n",
    "        continue\n",
    "    n_iter += 1\n",
    "    if n_iter % 5 == 1:\n",
    "        print(f'iter: {start + n_iter}/{stop}', flush=True)\n",
    "\n",
    "    input_image = d['jpg']\n",
    "    input_text = d['txt'].split(\"\\n\")[df_results.loc[i, \"best_text_id\"].item()]\n",
    "    \n",
    "    game = src.game_openai.CLIPGame(\n",
    "        model, preprocess, \n",
    "        input_image=input_image,\n",
    "        input_text=input_text,\n",
    "        patch_size=16 if MODEL_NAME.endswith(\"16\") else 32,\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "\n",
    "    path_file = os.path.join(PATH_INPUT, MODEL_NAME, MODE, f'iv_order2_{i}.pkl')\n",
    "    iv_object = shapiq.InteractionValues.load(path_file)\n",
    "\n",
    "    ## baseline\n",
    "    coalition_matrix_deletion_mif, coalition_matrix_deletion_lif = src.clique.get_cliques_greedy_mif_lif(iv=iv_object)\n",
    "    predictions_deletion_mif = game.value_function(np.concatenate((coalition_matrix_deletion_mif, [game.empty_coalition]), axis=0))\n",
    "    predictions_deletion_lif = game.value_function(np.concatenate((coalition_matrix_deletion_lif, [game.empty_coalition]), axis=0))\n",
    "\n",
    "    ## bad\n",
    "    # attribution_values = src.utils.convert_iv_to_first_order(iv_object, p_sampler=0.5).get_n_order(1).values\n",
    "    # attribution_values = src.utils.convert_iv_to_first_order(iv_object, p_sampler=1).get_n_order(1).values\n",
    "    # attribution_values = src.utils.convert_exclip_to_first_order(iv_object, game.n_players_image, game.n_players_text).get_n_order(1).values\n",
    "    # attribution_values_sorted = np.sort(attribution_values)\n",
    "    # coalition_matrix_deletion_mif = np.stack([attribution_values <= v for v in attribution_values_sorted[::-1]] + [game.empty_coalition])\n",
    "    # predictions_deletion_mif = game.value_function(coalition_matrix_deletion_mif)\n",
    "    # coalition_matrix_deletion_lif = np.stack([attribution_values >= v for v in attribution_values_sorted] + [game.empty_coalition])\n",
    "    # predictions_deletion_lif = game.value_function(coalition_matrix_deletion_lif)\n",
    "    \n",
    "    ## worse\n",
    "    # coalition_matrix_deletion_mif, coalition_matrix_deletion_lif = src.clique.get_cliques_greedy_mif_lif(iv=iv_object, return_complement=True)\n",
    "    # predictions_deletion_mif = game.value_function(np.concatenate(([game.empty_coalition == False], coalition_matrix_deletion_lif[::-1]), axis=0))\n",
    "    # predictions_deletion_lif = game.value_function(np.concatenate(([game.empty_coalition == False], coalition_matrix_deletion_mif[::-1]), axis=0))\n",
    "    \n",
    "    results_details[MODE][i] = {\n",
    "        'predictions_deletion_mif': predictions_deletion_mif,\n",
    "        'predictions_deletion_lif': predictions_deletion_lif,\n",
    "    }\n",
    "\n",
    "    assert predictions_deletion_mif[-1] == predictions_deletion_lif[-1]\n",
    "    assert predictions_deletion_mif[0] == predictions_deletion_lif[0]\n",
    "    \n",
    "    # normalize the curve\n",
    "    min_value = predictions_deletion_mif[-1]\n",
    "    max_value = predictions_deletion_mif[0]\n",
    "\n",
    "    predictions_deletion_mif_01 = (predictions_deletion_mif - min_value) / (max_value - min_value)\n",
    "    predictions_deletion_lif_01 = (predictions_deletion_lif - min_value) / (max_value - min_value)\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'input': [i], \n",
    "        'mode': [MODE], \n",
    "        'mean': [np.mean(predictions_deletion_lif - predictions_deletion_mif)],\n",
    "        'mean_normalized': [np.mean(predictions_deletion_lif_01 - predictions_deletion_mif_01)]\n",
    "    })])\n",
    "\n",
    "    if n_iter == 1 or n_iter % 5 == 0:\n",
    "        results.to_csv(os.path.join(PATH_RESULTS, MODEL_NAME, f'mscoco_aid_exclip.csv'), index=False)\n",
    "        np.save(os.path.join(PATH_RESULTS, MODEL_NAME, f'mscoco_aid_exclip.npy'), results_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc09c4",
   "metadata": {},
   "source": [
    "### visualize explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0390050",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT = \"../results\"\n",
    "PATH_OUTPUT = \"../results/mscoco\"\n",
    "\n",
    "path_output = os.path.join(PATH_OUTPUT, MODEL_NAME, MODE)\n",
    "if not os.path.exists(path_output):\n",
    "    os.makedirs(path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"clip-benchmark/wds_mscoco_captions\",\n",
    "    split=\"test\",\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca914ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(os.path.join(PATH_INPUT, MODEL_NAME, \"mscoco_predictions.csv\"), index_col=0)\n",
    "top_ids = df_results.sort_values(\"logit\").tail(1000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_counter = 0\n",
    "for i, d in enumerate(dataset):\n",
    "    if i not in top_ids:\n",
    "        continue\n",
    "    if print_counter % 100 == 0:\n",
    "        print(f'{MODE} | iter: {print_counter}/1000', flush=True)\n",
    "    print_counter += 1\n",
    "\n",
    "    input_image = d['jpg']\n",
    "    image_preprocessed = preprocess(input_image).to(device).unsqueeze(0)\n",
    "    input_text = d['txt'].split(\"\\n\")[df_results.loc[i, \"best_text_id\"].item()]\n",
    "    text_processed = clip.tokenize([input_text]).to(device)\n",
    "    \n",
    "    explanation = exCLIP(model, device=device)\n",
    "    output = explanation.attribute_prediction(\n",
    "        text_processed, \n",
    "        image_preprocessed, \n",
    "        text_layer=11, \n",
    "        image_layer=11,\n",
    "        N=20\n",
    "    )\n",
    "    crossmodal_interactions = output[1:-1,1:]\n",
    "    gv = src.utils.convert_array_to_second_order(crossmodal_interactions, index=\"exclip\")\n",
    "    gv.save(os.path.join(path_output, f'iv_order2_{i}.pkl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c828c",
   "metadata": {},
   "source": [
    "### pointing game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52565e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMES = [\n",
    "    ['goldfish', 'husky', 'pizza', 'tractor'],\n",
    "    ['cat', 'goldfish', 'plane', 'pizza'],\n",
    "    ['banana', 'cat', 'tractor', 'ball'],\n",
    "    ['husky', 'banana', 'plane', 'church'],\n",
    "    ['pizza', 'ipod', 'goldfish', 'banana'],\n",
    "    ['ipod', 'cat', 'husky', 'plane'],\n",
    "    ['tractor', 'ball', 'banana', 'ipod'],\n",
    "    ['plane', 'church', 'ball', 'goldfish'],\n",
    "    ['church', 'pizza', 'ipod', 'cat'],\n",
    "    ['ball', 'husky', 'banana', 'tractor'],\n",
    "]\n",
    "PATH_OUTPUT = \"../results/imagenet_pointing_game\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in GAMES:\n",
    "    PATH_INPUT = f'../data/imagenet_pointing_game/{\"_\".join(game)}'\n",
    "    print(game)\n",
    "    for i_objects in range(1, 5):\n",
    "        class_labels = game[:i_objects]\n",
    "        cl = \"_\".join(class_labels)\n",
    "        input_text = cl.replace(\"_\", \" \")\n",
    "        text_processed = clip.tokenize([input_text]).to(device)\n",
    "        path_output = os.path.join(PATH_OUTPUT, MODEL_NAME, MODE, cl)\n",
    "        if not os.path.exists(path_output):\n",
    "            os.makedirs(path_output)\n",
    "        for i_image in range(50):\n",
    "            input_image = Image.open(os.path.join(PATH_INPUT, f'{i_image}.jpg'))\n",
    "            image_preprocessed = preprocess(input_image).to(device).unsqueeze(0)\n",
    "\n",
    "            explanation = exCLIP(model, device=device)\n",
    "            output = explanation.attribute_prediction(\n",
    "                text_processed, \n",
    "                image_preprocessed, \n",
    "                text_layer=11, \n",
    "                image_layer=11,\n",
    "                N=20\n",
    "            )\n",
    "            crossmodal_interactions = output[1:-1,1:]\n",
    "            gv = src.utils.convert_array_to_second_order(crossmodal_interactions, index=\"exclip\")\n",
    "            gv.save(os.path.join(path_output, f'iv_order2_{i_image}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmti-gradeclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
