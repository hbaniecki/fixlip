{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9676b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shapiq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import src\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT = \"../results/imagenet_pointing_game\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(\n",
    "    iterable,\n",
    "    min_size: int = 0,\n",
    "    max_size: int | None = None,\n",
    "):\n",
    "    s = sorted(iterable)\n",
    "    max_size = len(s) if max_size is None else min(max_size, len(s))\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(max(min_size, 0), max_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48688aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_players = {\n",
    "    7: {\n",
    "        0: np.tile(range(0, 3), 3) + np.repeat(np.arange(0, 3) * 7, 3),\n",
    "        1: np.tile(range(4, 7), 3) + np.repeat(np.arange(0, 3) * 7, 3),\n",
    "        2: np.tile(range(0, 3), 3) + np.repeat(np.arange(0, 3) * 7, 3) + 7 * 4,\n",
    "        3: np.tile(range(4, 7), 3) + np.repeat(np.arange(0, 3) * 7, 3) + 7 * 4\n",
    "    },\n",
    "    # 7: {\n",
    "    #     0: np.tile(range(0, 4), 4) + np.repeat(np.arange(0, 4) * 7, 4),\n",
    "    #     1: np.tile(range(3, 7), 4) + np.repeat(np.arange(0, 4) * 7, 4),\n",
    "    #     2: np.tile(range(0, 4), 4) + np.repeat(np.arange(0, 4) * 7, 4) + 7 * 4,\n",
    "    #     3: np.tile(range(3, 7), 4) + np.repeat(np.arange(0, 4) * 7, 4) + 7 * 4\n",
    "    # },\n",
    "    8: {\n",
    "        0: np.tile(range(0, 4), 4) + np.repeat(np.arange(0, 4) * 8, 4),\n",
    "        1: np.tile(range(4, 8), 4) + np.repeat(np.arange(0, 4) * 8, 4),\n",
    "        2: np.tile(range(0, 4), 4) + np.repeat(np.arange(0, 4) * 8, 4) + 8 * 4,\n",
    "        3: np.tile(range(4, 8), 4) + np.repeat(np.arange(0, 4) * 8, 4) + 8 * 4\n",
    "    },\n",
    "    14: {\n",
    "        0: np.tile(range(0, 7), 7) + np.repeat(np.arange(7) * 14, 7),\n",
    "        1: np.tile(range(7, 14), 7) + np.repeat(np.arange(7) * 14, 7),\n",
    "        2: np.tile(range(0, 7), 7) + np.repeat(np.arange(7) * 14, 7) + 14 * 7,\n",
    "        3: np.tile(range(7, 14), 7) + np.repeat(np.arange(7) * 14, 7) + 14 * 7\n",
    "    },\n",
    "    16: {\n",
    "        0: np.tile(range(0, 8), 8) + np.repeat(np.arange(8) * 16, 8),\n",
    "        1: np.tile(range(8, 16), 8) + np.repeat(np.arange(8) * 16, 8),\n",
    "        2: np.tile(range(0, 8), 8) + np.repeat(np.arange(8) * 16, 8) + 16 * 8,\n",
    "        3: np.tile(range(8, 16), 8) + np.repeat(np.arange(8) * 16, 8) + 16 * 8\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cba0cd",
   "metadata": {},
   "source": [
    "## fixlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "# MODEL_NAME = \"openai/clip-vit-base-patch16\"\n",
    "# MODEL_NAME = \"google/siglip2-base-patch32-256\"\n",
    "# MODEL_NAME = \"google/siglip2-base-patch16-224\"\n",
    "MODEL_NAME = \"google/siglip2-large-patch16-256\"\n",
    "# MODEL_NAME = \"google/siglip-base-patch16-224\"\n",
    "# MODEL_NAME = \"google/siglip-large-patch16-256\"\n",
    "MODE = \"banzhaf_crossmodal\"\n",
    "# MODE = \"shapley\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'order': [], \n",
    "    'p_sampler': [],\n",
    "    'text_input': [], \n",
    "    'n_objects': [],\n",
    "    'image_id': [], \n",
    "\n",
    "    'clique_ratio_correct': [],\n",
    "    'mass_ratio_correct': [], \n",
    "    'mass_correct': [], \n",
    "    'mass_wrong': [], \n",
    "    'mass_total': [], \n",
    "    'sign_ratio_correct': [],\n",
    "})\n",
    "for order in [\n",
    "    1, \n",
    "    2\n",
    "]:\n",
    "    if MODE.startswith(\"banzhaf\"):\n",
    "        for p_sampler in [\n",
    "            \"0.5\", \n",
    "            # \"0.3\", \n",
    "            # \"0.7\"\n",
    "        ]:\n",
    "            for input_text in os.listdir(os.path.join(PATH_INPUT, MODEL_NAME, MODE, p_sampler)):\n",
    "                class_labels = input_text.split(\"_\")\n",
    "                #:# siglip\n",
    "                # if \"husky\" in class_labels or \"ipod\" in class_labels or \"goldfish\" in class_labels:\n",
    "                #     continue\n",
    "                #:# siglip-2\n",
    "                if \"ipod\" in class_labels or \"goldfish\" in class_labels:\n",
    "                    continue\n",
    "                n_players_text = len(class_labels)\n",
    "                for image_id in range(50):\n",
    "                    path_file = os.path.join(PATH_INPUT, MODEL_NAME, MODE, p_sampler, input_text, f'iv_order{order}_{image_id}.pkl')\n",
    "                    try:\n",
    "                        iv = shapiq.InteractionValues.load(path_file)\n",
    "                    except:\n",
    "                        # print(path_file)\n",
    "                        continue\n",
    "                    n_players_image = iv.n_players - n_players_text\n",
    "                    grid_size = int(np.sqrt(n_players_image))\n",
    "                    grid_ids = grid_players[grid_size]\n",
    "                    mass_correct, mass_wrong = 0, 0\n",
    "                    clique_value_correct, clique_ratio_correct = 0, 0\n",
    "                    sign_correct = 0\n",
    "\n",
    "                    fixlip = src.utils.get_crossmodal_subset(iv, n_players_image, n_players_text)\n",
    "\n",
    "                    # full_graph_value = (fixlip.values.sum() - fixlip.baseline_value).item()\n",
    "                    for token_id, token_text in enumerate(class_labels):\n",
    "                        image_players_in = grid_ids[token_id]\n",
    "                        text_players_out = n_players_image + np.array([e for e in range(len(class_labels)) if e != token_id])\n",
    "                        image_players_out = np.concat([grid_ids[e] for e in range(4) if e != token_id])\n",
    "                        if order == 1:\n",
    "                            iv_subset_in = src.utils.get_subset(fixlip, players=np.append(image_players_in, n_players_image + token_id), rename_players=False)\n",
    "                            iv_subset_out = src.utils.get_subset(fixlip, players=np.append(image_players_out, n_players_image + token_id), rename_players=False)\n",
    "                            # iv_subset_in = src.utils.get_subset(fixlip, players=image_players_in, rename_players=False)\n",
    "                            # iv_subset_out = src.utils.get_subset(fixlip, players=image_players_out, rename_players=False)\n",
    "                            values_in = iv_subset_in.get_n_order(1).values\n",
    "                            values_out = iv_subset_out.get_n_order(1).values       \n",
    "                        elif order == 2:\n",
    "                            iv_subset_in = src.utils.get_subset(fixlip, players=np.append(image_players_in, n_players_image + token_id), rename_players=False)\n",
    "                            iv_subset_out = src.utils.get_subset(fixlip, players=np.append(image_players_out, n_players_image + token_id), rename_players=False)\n",
    "                            values_in = iv_subset_in.get_n_order(2).values\n",
    "                            values_out = iv_subset_out.get_n_order(2).values\n",
    "                            \n",
    "                        n_values = len(values_in) + len(values_out)\n",
    "                        \n",
    "                        sign_correct += ((values_in > 0).sum().item() + (values_out < 0).sum().item()) / n_values\n",
    "\n",
    "                        mass_correct += values_in[values_in > 0].sum().item() + np.abs(values_out[values_out < 0]).sum().item()\n",
    "                        mass_wrong += values_out[values_out > 0].sum().item() + np.abs(values_in[values_in < 0]).sum().item()\n",
    "\n",
    "                    results = pd.concat([results, pd.DataFrame({\n",
    "                        'order': [order],\n",
    "                        'p_sampler': [p_sampler],\n",
    "                        'text_input': [\" \".join(class_labels)], \n",
    "                        'n_objects': [len(class_labels)], \n",
    "                        'image_id': [image_id], \n",
    "                        'mass_ratio_correct': [mass_correct / (mass_correct + mass_wrong)], \n",
    "                        'mass_correct': [mass_correct], \n",
    "                        'mass_wrong': [mass_wrong], \n",
    "                        'mass_total': [mass_correct + mass_wrong],\n",
    "                        'sign_ratio_correct': [sign_correct / len(class_labels)],\n",
    "                    })])\n",
    "    elif MODE == \"shapley\":\n",
    "        for input_text in os.listdir(os.path.join(PATH_INPUT, MODEL_NAME, MODE)):\n",
    "            class_labels = input_text.split(\"_\")\n",
    "            n_players_text = len(class_labels)\n",
    "            for image_id in range(50):\n",
    "                path_file = os.path.join(PATH_INPUT, MODEL_NAME, MODE, input_text, f'iv_order{order}_{image_id}.pkl')\n",
    "                try:\n",
    "                    iv = shapiq.InteractionValues.load(path_file)\n",
    "                except:\n",
    "                    # print(path_file)\n",
    "                    continue\n",
    "                n_players_image = iv.n_players - n_players_text\n",
    "                grid_size = int(np.sqrt(n_players_image))\n",
    "                grid_ids = grid_players[grid_size]\n",
    "                mass_correct, mass_wrong = 0, 0\n",
    "                clique_value_correct, clique_ratio_correct = 0, 0\n",
    "                sign_correct = 0\n",
    "\n",
    "                fixlip = src.utils.get_crossmodal_subset(iv, n_players_image, n_players_text)\n",
    "\n",
    "                for token_id, token_text in enumerate(class_labels):\n",
    "                    image_players_in = grid_ids[token_id]\n",
    "                    text_players_out = n_players_image + np.array([e for e in range(len(class_labels)) if e != token_id])\n",
    "                    image_players_out = np.concat([grid_ids[e] for e in range(4) if e != token_id])\n",
    "                    if order == 1:\n",
    "                        iv_subset_in = src.utils.get_subset(fixlip, players=np.append(image_players_in, n_players_image + token_id), rename_players=False)\n",
    "                        iv_subset_out = src.utils.get_subset(fixlip, players=np.append(image_players_out, n_players_image + token_id), rename_players=False)\n",
    "                        # iv_subset_in = src.utils.get_subset(fixlip, players=image_players_in, rename_players=False)\n",
    "                        # iv_subset_out = src.utils.get_subset(fixlip, players=image_players_out, rename_players=False)\n",
    "                        values_in = iv_subset_in.get_n_order(1).values\n",
    "                        values_out = iv_subset_out.get_n_order(1).values       \n",
    "                    elif order == 2:\n",
    "                        iv_subset_in = src.utils.get_subset(fixlip, players=np.append(image_players_in, n_players_image + token_id), rename_players=False)\n",
    "                        iv_subset_out = src.utils.get_subset(fixlip, players=np.append(image_players_out, n_players_image + token_id), rename_players=False)\n",
    "                        values_in = iv_subset_in.get_n_order(2).values\n",
    "                        values_out = iv_subset_out.get_n_order(2).values\n",
    "                        \n",
    "                    n_values = len(values_in) + len(values_out)\n",
    "                    \n",
    "                    sign_correct += ((values_in > 0).sum().item() + (values_out < 0).sum().item()) / n_values\n",
    "\n",
    "                    mass_correct += values_in[values_in > 0].sum().item() + np.abs(values_out[values_out < 0]).sum().item()\n",
    "                    mass_wrong += values_out[values_out > 0].sum().item() + np.abs(values_in[values_in < 0]).sum().item()\n",
    "\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    'order': [order],\n",
    "                    'text_input': [\" \".join(class_labels)], \n",
    "                    'n_objects': [len(class_labels)], \n",
    "                    'image_id': [image_id], \n",
    "                    'mass_ratio_correct': [mass_correct / (mass_correct + mass_wrong)], \n",
    "                    'mass_correct': [mass_correct], \n",
    "                    'mass_wrong': [mass_wrong], \n",
    "                    'mass_total': [mass_correct + mass_wrong],\n",
    "                    'sign_ratio_correct': [sign_correct / len(class_labels)],\n",
    "                })])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"order\", \"p_sampler\", \"n_objects\"]).aggregate({\n",
    "    'mass_ratio_correct': ['mean', 'std']\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"order\", \"n_objects\"]).aggregate({\n",
    "    'mass_ratio_correct': ['mean', 'std']\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe43e48",
   "metadata": {},
   "source": [
    "## baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'model_name': [],\n",
    "    'mode': [],\n",
    "    'text_input': [], \n",
    "    'n_objects': [],\n",
    "    'image_id': [], \n",
    "    'mass_ratio_correct': [], \n",
    "    'mass_correct': [], \n",
    "    'mass_wrong': [], \n",
    "    'mass_total': [], \n",
    "    'sign_ratio_correct': [],\n",
    "})\n",
    "for model_name in [\n",
    "    \"openai/clip-vit-base-patch32\",\n",
    "    \"openai/clip-vit-base-patch16\"\n",
    "]:\n",
    "    for mode in [\n",
    "        # 'game',\n",
    "        # 'gradeclip',\n",
    "        'exclip',\n",
    "    ]:\n",
    "        for input_text in os.listdir(os.path.join(PATH_INPUT, model_name, mode)):\n",
    "            class_labels = input_text.split(\"_\")\n",
    "            n_players_text = len(class_labels)\n",
    "            for image_id in range(50):\n",
    "                if mode in ['game', 'gradeclip']:\n",
    "                    path_file = os.path.join(PATH_INPUT, model_name, mode, input_text, f'iv_order1_{image_id}.pkl')\n",
    "                elif mode.startswith('exclip'):\n",
    "                    path_file = os.path.join(PATH_INPUT, model_name, mode, input_text, f'iv_order2_{image_id}.pkl')\n",
    "                try:\n",
    "                    iv = shapiq.InteractionValues.load(path_file)\n",
    "                except:\n",
    "                    # print(path_file)\n",
    "                    continue\n",
    "                n_players_image = iv.n_players - n_players_text\n",
    "                grid_size = int(np.sqrt(n_players_image))\n",
    "                grid_ids = grid_players[grid_size]\n",
    "                mass_correct, mass_wrong = 0, 0\n",
    "                sign_correct = 0\n",
    "\n",
    "                for token_id, token_text in enumerate(class_labels):\n",
    "                    image_players_in = grid_ids[token_id]\n",
    "                    text_players_out = n_players_image + np.array([e for e in range(len(class_labels)) if e != token_id])\n",
    "                    image_players_out = np.concat([grid_ids[e] for e in range(4) if e != token_id])\n",
    "\n",
    "                    if mode in ['game', 'gradeclip']:\n",
    "                        iv_subset_in = src.utils.get_subset(iv, players=np.append(image_players_in, n_players_image + token_id), rename_players=False)\n",
    "                        iv_subset_out = src.utils.get_subset(iv, players=np.append(image_players_out, n_players_image + token_id), rename_players=False)\n",
    "                        values_in = iv_subset_in.get_n_order(1).values\n",
    "                        values_out = iv_subset_out.get_n_order(1).values       \n",
    "                    elif mode.startswith('exclip'):\n",
    "                        iv_subset_in = src.utils.get_subset(iv, players=np.append(image_players_in, n_players_image + token_id), rename_players=False)\n",
    "                        iv_subset_out = src.utils.get_subset(iv, players=np.append(image_players_out, n_players_image + token_id), rename_players=False)\n",
    "                        values_in = iv_subset_in.get_n_order(2).values\n",
    "                        values_out = iv_subset_out.get_n_order(2).values\n",
    "\n",
    "                    n_values = len(values_in) + len(values_out)\n",
    "                    \n",
    "                    sign_correct += ((values_in > 0).sum().item() + (values_out < 0).sum().item()) / n_values\n",
    "\n",
    "                    mass_correct += values_in[values_in > 0].sum().item() + np.abs(values_out[values_out < 0]).sum().item()\n",
    "                    mass_wrong += values_out[values_out > 0].sum().item() + np.abs(values_in[values_in < 0]).sum().item()\n",
    "\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    'model_name': [model_name],\n",
    "                    'mode': [mode],\n",
    "                    'text_input': [\" \".join(class_labels)], \n",
    "                    'n_objects': [len(class_labels)], \n",
    "                    'image_id': [image_id], \n",
    "                    'mass_ratio_correct': [mass_correct / (mass_correct + mass_wrong)], \n",
    "                    'mass_correct': [mass_correct], \n",
    "                    'mass_wrong': [mass_wrong], \n",
    "                    'mass_total': [mass_correct + mass_wrong],\n",
    "                    'sign_ratio_correct': [sign_correct / len(class_labels)],\n",
    "                })])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"model_name\", \"mode\", \"n_objects\"]).aggregate({\n",
    "    'mass_ratio_correct': ['mean', 'std'],\n",
    "}).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
